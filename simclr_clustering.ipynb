{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5852c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LazyDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimCLRTransform:\n",
    "    def __init__(self, size=224):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=9),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x), self.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, base_encoder=models.resnet18, projection_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder(pretrained=False)\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return F.normalize(z, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.5):\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "    N = z.size(0)\n",
    "    labels = torch.arange(N // 2, device=z.device).repeat(2)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    mask = torch.eye(N, dtype=torch.bool, device=z.device)\n",
    "    sim = sim[~mask].view(N, -1)\n",
    "    labels = labels[~mask].view(N, -1)\n",
    "    sim /= temperature\n",
    "    loss = -torch.log(\n",
    "        torch.exp(sim) * labels / torch.exp(sim).sum(dim=1, keepdim=True)\n",
    "    )\n",
    "    return loss.sum() / (2 * (N // 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adfe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_simclr(model, dataloader, optimizer, device, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for (x1, x2) in dataloader:\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "            z1, z2 = model(x1), model(x2)\n",
    "            loss = nt_xent_loss(z1, z2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_embeddings(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for x in dataloader:\n",
    "            x = x.to(device)\n",
    "            h = model.encoder(x)\n",
    "            features.append(h.cpu())\n",
    "    return torch.cat(features).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_embeddings(embeddings, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto')\n",
    "    y_pred = kmeans.fit_predict(embeddings)\n",
    "    sil_score = silhouette_score(embeddings, y_pred)\n",
    "    ch_score = calinski_harabasz_score(embeddings, y_pred)\n",
    "    return y_pred, sil_score, ch_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d5785",
   "metadata": {},
   "source": [
    "# Dataset Boold Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1713be",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"blood_cell/blood_cell/segmenter\"\n",
    "\n",
    "GPU = True\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "transform = SimCLRTransform()\n",
    "dataset = LazyDataset(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "model = SimCLRModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_simclr(model, dataloader, optimizer, device, epochs=EPOCHS)\n",
    "\n",
    "# Para extraer embeddings sin augmentaciones\n",
    "eval_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "eval_dataset = LazyDataset(IMAGE_DIR, transform=eval_transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "embeddings = extract_embeddings(model, eval_loader, device)\n",
    "y_pred, sil_score, ch_score = cluster_embeddings(embeddings, n_clusters=10)\n",
    "print(\"Silhouette Score:\", sil_score)\n",
    "print(\"Calinski-Harabasz Score:\", ch_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad36698",
   "metadata": {},
   "source": [
    "# Dataset CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"cifar-10/cifar-10/cifar-10-batches-py\"\n",
    "\n",
    "GPU = True\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "transform = SimCLRTransform()\n",
    "dataset = LazyDataset(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "model = SimCLRModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_simclr(model, dataloader, optimizer, device, epochs=EPOCHS)\n",
    "\n",
    "# Para extraer embeddings sin augmentaciones\n",
    "eval_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "eval_dataset = LazyDataset(IMAGE_DIR, transform=eval_transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "embeddings = extract_embeddings(model, eval_loader, device)\n",
    "y_pred, sil_score, ch_score = cluster_embeddings(embeddings, n_clusters=10)\n",
    "print(\"Silhouette Score:\", sil_score)\n",
    "print(\"Calinski-Harabasz Score:\", ch_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
